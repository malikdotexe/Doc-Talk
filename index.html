
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>Talk to Your Documents ‚Äì Gemini Live + LangChain</title>
  <link rel="stylesheet"
    href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Material+Icons&display=swap">
  <style>
    body { font-family: 'Inter', sans-serif; margin: 0; background: #f9fafc; color: #333; }
    header { background: linear-gradient(90deg, #4a00e0, #8e2de2); color: white; padding: 24px 40px; font-size: 22px; font-weight: 700; display: flex; justify-content: space-between; align-items: center; }
    .hero { text-align: center; padding: 80px 20px; background: linear-gradient(135deg, #fdfbfb, #ebedee); }
    .hero h1 { font-size: 48px; margin-bottom: 16px; }
    .hero p { font-size: 20px; color: #555; margin-bottom: 24px; }
    .cta-btn { background: #4a00e0; color: white; padding: 14px 24px; border: none; border-radius: 8px; margin: 0 10px; font-size: 16px; cursor: pointer; }
    .container { display: flex; justify-content: center; gap: 40px; padding: 60px; flex-wrap: wrap; }
    .card { background: white; border-radius: 20px; padding: 24px; box-shadow: 0 6px 20px rgba(0,0,0,0.08); flex: 1; min-width: 360px; max-width: 600px; }
    .features { display: grid; grid-template-columns: repeat(auto-fit,minmax(220px,1fr)); gap: 24px; padding: 60px; text-align: center; }
    .features h3 { margin-top: 12px; font-size: 18px; }
    footer { text-align: center; padding: 20px; background: #f1f1f1; font-size: 14px; color: #777; }
  </style>
</head>

<body>
  <header>
    <div>Talk to Your Documents</div>
    <span>‚Äì by Piyush Malik</span>
  </header>

  <section class="hero">
    <h1>Talk to Your Documents</h1>
        <div style="margin:20px; text-align:center;">
    <input type="password" id="apiKeyInput" placeholder="Enter your Gemini API Key"
            style="padding:10px; width:300px; border-radius:8px; border:1px solid #ccc;">
    <button onclick="saveKey()" style="padding:10px 20px; margin-left:10px;">Save</button>
    </div>

    <p>Upload PDFs. Ask questions. Get instant answers with Gemini Live + LangChain.</p>
    <button class="cta-btn" onclick="document.getElementById('pdfInput').click()">Upload a PDF</button>
    <button class="cta-btn" onclick="document.getElementById('startButton').click()">Start Talking</button>
  </section>

  <main class="container">
    <!-- Left: PDF + Voice -->
    <div class="card">
      <div class="button-group">
        <button id="startButton" class="cta-btn"><i class="material-icons">mic</i> Start</button>
        <button id="stopButton" class="cta-btn" style="background:#9e9e9e;"><i class="material-icons">mic_off</i> Stop</button>
      </div>
      <input type="file" id="pdfInput" accept="application/pdf" style="margin-top:20px;">
      <div id="pdf-container" style="display:none; margin-top:20px;">
        <embed id="pdfPreview" type="application/pdf" style="width:100%; height:400px; border-radius:12px;"/>
      </div>
    </div>

    <!-- Right: Chat -->
    <div class="card">
      <h3>Chat</h3>
      <div id="chatLog" style="height:500px; overflow-y:auto; border:1px solid #ddd; border-radius:12px; padding:16px;"></div>
    </div>
  </main>

  <section class="features">
    <div>
      <div style="font-size:32px;">üéôÔ∏è</div>
      <h3>Voice-first Experience</h3>
      <p>Talk naturally with your documents in real time.</p>
    </div>
    <div>
      <div style="font-size:32px;">‚ö°</div>
      <h3>Instant Answers</h3>
      <p>Powered by Gemini Live + LangChain for contextual insights.</p>
    </div>
    <div>
      <div style="font-size:32px;">üìÑ</div>
      <h3>PDF Understanding</h3>
      <p>Upload reports, contracts, or notes and query instantly.</p>
    </div>
  </section>

  <footer>
    ¬© 2025 Talk to Your Documents. Built with ‚ù§Ô∏è using Gemini Live + LangChain ‚Äì by Piyush Malik
  </footer>

  <!-- Insert your existing WebSocket + audio + PDF handling JS here -->
<script defer>
  const URL = "ws://localhost:9084";

  // ==== WebSocket globals ====
  let webSocket = null;

  // ==== Audio globals ====
  let audioContext = null;
  let micStream = null;
  let mediaSource = null;
  let processor = null;
  let pcmData = [];
  let chunkTimer = null;
  let isRecording = false;

  // ==== Playback context (for Gemini audio output) ====
  let audioInputContext;
  let workletNode;
  let initialized = false;

  // ==== DOM elements ====
  const pdfInput = document.getElementById("pdfInput");
  const pdfPreview = document.getElementById("pdfPreview");
  const pdfContainer = document.getElementById("pdf-container");
  const startBtn = document.getElementById("startButton");
  const stopBtn = document.getElementById("stopButton");

  // ====== PDF handling ======
  window.addEventListener("load", async () => {
    pdfInput.addEventListener("change", async (event) => {
      console.log("pdfInput change event detected!");
      const file = event.target.files[0];

      if (file && file.type === "application/pdf") {
        const reader = new FileReader();

        reader.onload = (e) => {
          pdfPreview.setAttribute("src", e.target.result);
          pdfContainer.style.display = "block";
          console.log("pdf rendered");

          // Convert to base64 and send immediately
          const base64Reader = new FileReader();
          base64Reader.onload = function (e) {
            try {
              const base64PDF = e.target.result.split(",")[1];
              sendPDFMessage(base64PDF, file.name);
            } catch (err) {
              console.error("error processing pdf file", err);
            }
          };
          base64Reader.onerror = (err) => {
            console.error("error reading pdf file", err);
          };
          base64Reader.readAsDataURL(file);
        };
        reader.readAsDataURL(file);
      } else {
        alert("Please select a valid PDF file.");
        pdfContainer.style.display = "none";
        pdfInput.value = ""; // Clear the file input
        pdfPreview.removeAttribute("src");
        console.warn("no pdf file detected");
      }
    });

    await initializeAudioContext();
    connect();
    setControls(false);
  });

  // ====== WebSocket connection ======
  function connect() {
    console.log("connecting: ", URL);

    webSocket = new WebSocket(URL);

    webSocket.onclose = (event) => {
      console.log("websocket closed: ", event);
      alert("Connection closed");
    };

    webSocket.onerror = (event) => {
      console.log("websocket error: ", event);
    };

    webSocket.onopen = (event) => {
      console.log("websocket open: ", event);
      sendInitialSetupMessage();
    };

    webSocket.onmessage = receiveMessage;
  }

  function sendInitialSetupMessage() {
    console.log("sending setup message");
    const setup_client_message = {
      setup: {
        generation_config: { response_modalities: ["AUDIO"] },
      },
    };

    webSocket.send(JSON.stringify(setup_client_message));
  }

  function sendPDFMessage(base64PDF, filename) {
    try {
      if (webSocket == null) {
        console.log("websocket not initialized");
        return;
      }

      const payload = {
        realtime_input: {
          media_chunks: [
            {
              mime_type: "application/pdf",
              data: base64PDF,
              filename: filename,
            },
          ],
        },
      };

      webSocket.send(JSON.stringify(payload));
      console.log("PDF data sent immediately");
    } catch (err) {
      console.error("Error sending PDF message:", err);
    }
  }

  function sendVoiceMessage(b64PCM) {
    try {
      if (webSocket == null) {
        console.log("websocket not initialized");
        return;
      }

      const payload = {
        realtime_input: {
          media_chunks: [
            {
              mime_type: "audio/pcm",
              data: b64PCM,
            },
          ],
        },
      };

      webSocket.send(JSON.stringify(payload));
      console.log("sent payload with audio data");
    } catch (err) {
      console.error("Error sending audio message:", err);
    }
  }

  // ====== WebSocket message handling ======
  function receiveMessage(event) {
    try {
      const messageData = JSON.parse(event.data);
      const response = new Response(messageData);

      if (response.text) {
        displayMessage("GEMINI: " + response.text);
      }
      if (response.audioData) {
        injestAudioChunkToPlay(response.audioData);
      }
    } catch (err) {
      console.error("Error receiving message:", err);
    }
  }

  // ====== Playback for Gemini audio ======
  async function initializeAudioContext() {
    if (initialized) return;

    audioInputContext = new (window.AudioContext ||
      window.webkitAudioContext)({
      sampleRate: 24000,
    });
    await audioInputContext.audioWorklet.addModule("pcm-processor.js");
    workletNode = new AudioWorkletNode(audioInputContext, "pcm-processor");
    workletNode.connect(audioInputContext.destination);
    initialized = true;
  }

  function base64ToArrayBuffer(base64) {
    const binaryString = window.atob(base64);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes.buffer;
  }

  function convertPCM16LEToFloat32(pcmData) {
    const inputArray = new Int16Array(pcmData);
    const float32Array = new Float32Array(inputArray.length);

    for (let i = 0; i < inputArray.length; i++) {
      float32Array[i] = inputArray[i] / 32768;
    }

    return float32Array;
  }

  async function injestAudioChunkToPlay(base64AudioChunk) {
    try {
      if (audioInputContext.state === "suspended") {
        await audioInputContext.resume();
      }
      const arrayBuffer = base64ToArrayBuffer(base64AudioChunk);
      const float32Data = convertPCM16LEToFloat32(arrayBuffer);

      workletNode.port.postMessage(float32Data);
    } catch (error) {
      console.error("Error processing audio chunk:", error);
    }
  }

  // ====== Recording / Stop ======
  async function startAudioInput() {
    if (isRecording) return;

    audioContext = new (window.AudioContext || window.webkitAudioContext)({
      sampleRate: 16000,
    });

    micStream = await navigator.mediaDevices.getUserMedia({
      audio: {
        channelCount: 1,
        sampleRate: 16000,
      },
    });

    mediaSource = audioContext.createMediaStreamSource(micStream);
    processor = audioContext.createScriptProcessor(4096, 1, 1);

    processor.onaudioprocess = (e) => {
      const inputData = e.inputBuffer.getChannelData(0);
      const pcm16 = new Int16Array(inputData.length);
      for (let i = 0; i < inputData.length; i++) {
        pcm16[i] = Math.max(-1, Math.min(1, inputData[i])) * 0x7fff;
      }
      pcmData.push(...pcm16);
    };

    mediaSource.connect(processor);
    processor.connect(audioContext.destination);

    if (chunkTimer) clearInterval(chunkTimer);
    chunkTimer = setInterval(recordChunk, 3000);

    isRecording = true;
    setControls(true);
  }

  async function stopAudioInput() {
    try {
      if (!isRecording) return;

      // stop timer
      if (chunkTimer) {
        clearInterval(chunkTimer);
        chunkTimer = null;
      }

      // disconnect nodes
      if (processor) {
        try {
          processor.disconnect();
        } catch {}
        processor.onaudioprocess = null;
        processor = null;
      }
      if (mediaSource) {
        try {
          mediaSource.disconnect();
        } catch {}
        mediaSource = null;
      }

      // stop mic
      if (micStream) {
        micStream.getTracks().forEach((t) => {
          try {
            t.stop();
          } catch {}
        });
        micStream = null;
      }

      // close context
      if (audioContext) {
        if (audioContext.state !== "closed") {
          try {
            await audioContext.close();
          } catch {}
        }
        audioContext = null;
      }

      pcmData = [];
      isRecording = false;
      setControls(false);
    } catch (err) {
      console.error("stopAudioInput error:", err);
    }
  }

  function recordChunk() {
    if (!pcmData.length) return;

    const buffer = new ArrayBuffer(pcmData.length * 2);
    const view = new DataView(buffer);
    pcmData.forEach((value, index) => {
      view.setInt16(index * 2, value, true);
    });

    const base64 = btoa(
      String.fromCharCode.apply(null, new Uint8Array(buffer))
    );

    sendVoiceMessage(base64);
    pcmData = [];
  }

  // ====== Chat UI ======
  function displayMessage(message) {
    console.log(message);
    addParagraphToDiv("chatLog", message);
  }

  function addParagraphToDiv(divId, text) {
    const newParagraph = document.createElement("p");
    newParagraph.textContent = text;
    const div = document.getElementById(divId);
    div.appendChild(newParagraph);
    div.scrollTop = div.scrollHeight;
  }

  // ====== Control state ======
  function setControls(recording) {
    if (startBtn) startBtn.disabled = recording;
    if (stopBtn) stopBtn.disabled = !recording;
  }

  // ====== Bind buttons ======
  startBtn.addEventListener("click", startAudioInput);
  stopBtn.addEventListener("click", stopAudioInput);

  // ====== Response class ======
  class Response {
    constructor(data) {
      this.text = null;
      this.audioData = null;
      this.endOfTurn = null;

      if (data.text) {
        this.text = data.text;
      }

      if (data.audio) {
        this.audioData = data.audio;
      }
    }
  }
  let userApiKey = null;

function saveKey() {
  const val = document.getElementById("apiKeyInput").value.trim();
  if (!val) {
    alert("Please enter a valid API key");
    return;
  }
  userApiKey = val;
  localStorage.setItem("gemini_api_key", val);
  alert("API key saved!");
}

// Load key from localStorage on page load
window.addEventListener("load", () => {
  const saved = localStorage.getItem("gemini_api_key");
  if (saved) {
    userApiKey = saved;
    document.getElementById("apiKeyInput").value = saved;
  }
});

</script>

</body>
</html>
